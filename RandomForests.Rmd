---
output:
  word_document: default
  html_document: default
---
## Jonathan Broadbridge

## Random Forest Assignment

## BAN 502 Module 4



```{r, include =FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(gridExtra)
#install.packages('vip')
library(vip)
library(ranger)
library(VIM)
library(skimr)
```

```{r}
drug <- read_csv('drug_data-1.csv')

names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity","Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive","SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis","Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh","LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")

drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"

drug_clean = drug %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44","45_54", "55_64", "65_"))) %>%mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%mutate(Education = factor(Education, labels =c("Under16", "At16", "At17", "At18", "SomeCollege","ProfessionalCert", "Bachelors", "Masters", "Doctorate"))) %>%mutate(Country = factor(Country,labels = c("USA", "NewZealand", "Other", "Australia","Ireland","Canada","UK"))) %>%mutate(Ethnicity = factor(Ethnicity,labels = c("Black", "Asian", "White", "White/Black", "Other","White/Asian", "Black/Asian"))) %>% mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%select(-ID)

#str(drug_clean)

drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA))
names(drug_clean)
```

```{r task 1}
skim(drug_clean)
```

```{r task 2}
set.seed(1234) 
drug_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) #70% in training
train = training(drug_split)
test = testing(drug_split)
```

```{r task 3}
p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)

p5 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
p6 = ggplot(train, aes(x = Nicotine, y = Nscore)) + geom_boxplot()
p7 = ggplot(train, aes(x = Nicotine, y = Escore)) + geom_boxplot()
p8 = ggplot(train, aes(x = Nicotine, y = Oscore)) + geom_boxplot()
grid.arrange(p5,p6,p7,p8)

p9 = ggplot(train, aes(x = Nicotine, y = Ascore)) + geom_boxplot()
p10 = ggplot(train, aes(x = Nicotine, y = Cscore)) + geom_boxplot()
p11 = ggplot(train, aes(x = Nicotine, y = Impulsive)) + geom_boxplot()
p12 = ggplot(train, aes(x = Nicotine, y = SS)) + geom_boxplot()
grid.arrange(p9,p10,p11,p12)
```

## task 3 summary

When examining the relationships between the response variable Nicotine and the predictive variables we see that some have significant trends to explore.
Age, gender, education, country and ethnicity all seem to be significant when examining the categorical variables. Impulsivity and sensation seeking appear to be the most significant quantitative variables.

```{r task 4}
drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

set.seed(123)
rf_folds = vfold_cv(train, v = 5)

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)


rf_grid = grid_regular(
  mtry(), #these values determined through significant trial and error
  min_n(), #these values determined through significant trial and error
  levels = 10
)

set.seed(123)
rf_res = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = rf_grid #use the tuning grid
)

rf_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```





```{r task 5}
rf_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")

best_rf = select_best(rf_res, "accuracy")

final_rf = finalize_workflow(
  drug_wflow,
  best_rf
)

final_rf

final_rf_fit = fit(final_rf, train)

final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")

trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)

confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")

testpredrf = predict(final_rf_fit, test)
head(testpredrf)
confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```

### Task 6 

When examining the predictive model on the training and testing sets we see signs that the model performs very well on the training model with an accuracy of ~91% when compared to the no information rate of 67%. The testing set however does not perform as well. The testing set has an accuracy of ~70% which is only marginally better than the no information rate.

### Task 7

Based on the results of the model on the testing and training sets I would assume that this model would not work well with new data. It may provide some value over the no information prediction however I would not recommend using this for real world use. I have concerns that the model is overfit to the training data and that the predictions may not be reliable.


